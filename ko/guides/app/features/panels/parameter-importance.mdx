---
title: Parameter importance
description: 모델의 하이퍼파라미터와 출력 메트릭 간의 관계를 시각화합니다.
menu:
  default:
    identifier: ko-guides-models-app-features-panels-parameter-importance
    parent: panels
weight: 60
---

어떤 하이퍼파라미터가 가장 예측력이 높고 메트릭의 바람직한 값과 상관관계가 높은지 알아보세요.

<Frame>
    <img src="/images/general/parameter-importance-1.png"  />
</Frame>

**상관 관계(Correlation)**는 하이퍼파라미터와 선택한 메트릭 (이 경우 val_loss) 간의 선형 상관 관계입니다. 따라서 상관 관계가 높다는 것은 하이퍼파라미터의 값이 높을 때 메트릭도 더 높은 값을 갖고 그 반대도 마찬가지임을 의미합니다. 상관 관계는 살펴보기에 좋은 메트릭이지만 입력 간의 2차 상호 작용을 포착할 수 없으며 범위가 매우 다른 입력을 비교하는 것이 복잡해질 수 있습니다.

따라서 W&B는 **중요도(importance)** 메트릭도 계산합니다. W&B는 하이퍼파라미터를 입력으로, 메트릭을 대상 출력으로 사용하여 랜덤 포레스트를 트레이닝하고 랜덤 포레스트에 대한 특징 중요도 값을 리포트합니다.

이 기술에 대한 아이디어는 [Fast.ai](http://fast.ai)에서 하이퍼파라미터 공간을 탐색하기 위해 랜덤 포레스트 특징 중요도를 사용하는 것을 개척한 [Jeremy Howard](https://twitter.com/jeremyphoward)와의 대화에서 영감을 받았습니다. 이 [강의](http://course18.fast.ai/lessonsml1/lesson4.html) (및 이 [노트](https://forums.fast.ai/t/wiki-lesson-thread-lesson-4/7540))를 확인하여 이 분석의 동기에 대해 자세히 알아보는 것이 좋습니다.

하이퍼파라미터 중요도 패널은 상관관계가 높은 하이퍼파라미터 간의 복잡한 상호 작용을 해결합니다. 이를 통해 모델 성능 예측 측면에서 가장 중요한 하이퍼파라미터를 보여줌으로써 하이퍼파라미터 검색을 미세 튜닝하는 데 도움이 됩니다.

## 하이퍼파라미터 중요도 패널 만들기

1. W&B **프로젝트**로 이동합니다.
2. **패널 추가** 버튼을 선택합니다.
3. **차트** 드롭다운을 확장하고 드롭다운에서 **평행 좌표**를 선택합니다.

<Note>
빈 패널이 나타나면 **Runs**이 그룹 해제되었는지 확인하십시오.
</Note>

<Frame>
    <img src="/images/app_ui/hyperparameter_importance_panel.gif" alt="Using automatic parameter visualization"  />
</Frame>

**파라미터** 관리자를 사용하면 표시 및 숨겨진 **파라미터**를 수동으로 설정할 수 있습니다.

<Frame>
    <img src="/images/app_ui/hyperparameter_importance_panel_manual.gif" alt="Manually setting the visible and hidden fields"  />
</Frame>

## 하이퍼파라미터 중요도 패널 해석하기

<Frame>
    <img src="/images/general/parameter-importance-4.png"  />
</Frame>

이 패널은 트레이닝 스크립트의 [wandb.config](/ko/guides/models/track/config/) **오브젝트**에 전달된 모든 **파라미터**를 보여줍니다. 다음으로 이러한 config **파라미터**의 특징 중요도와 모델 메트릭과 관련된 상관 관계를 보여줍니다 (이 경우 `val_loss`).

### 중요도

중요도 열은 각 하이퍼파라미터가 선택한 메트릭을 예측하는 데 얼마나 유용한지를 보여줍니다. 수많은 하이퍼파라미터를 튜닝하기 시작하고 이 플롯을 사용하여 추가 탐색할 가치가 있는 하이퍼파라미터를 정확히 찾아내는 시나리오를 상상해 보십시오. 후속 **스윕**은 가장 중요한 하이퍼파라미터로 제한되어 더 좋고 저렴한 모델을 더 빠르게 찾을 수 있습니다.

<Note>
W&B는 선형 모델보다 트리 기반 모델을 사용하여 중요도를 계산합니다. 전자는 범주형 데이터와 정규화되지 않은 데이터 모두에 더 관대하기 때문입니다.
</Note>

위의 이미지에서 `epochs`, `learning_rate`, `batch_size` 및 `weight_decay`가 상당히 중요하다는 것을 알 수 있습니다.

### 상관 관계

상관 관계는 개별 하이퍼파라미터와 메트릭 값 간의 선형 관계를 캡처합니다. SGD **옵티마이저**와 같은 하이퍼파라미터를 사용하는 것과 `val_loss` 사이에 중요한 관계가 있는지에 대한 질문에 답합니다 (이 경우 답은 '예'입니다). 상관 관계 값은 -1에서 1 사이이며, 양수 값은 양의 선형 상관 관계를 나타내고 음수 값은 음의 선형 상관 관계를 나타내고 값 0은 상관 관계가 없음을 나타냅니다. 일반적으로 어느 방향이든 0.7보다 큰 값은 강한 상관 관계를 나타냅니다.

이 그래프를 사용하여 메트릭과 더 높은 상관 관계가 있는 값을 추가로 탐색하거나 (이 경우 rmsprop 또는 nadam보다 stochastic gradient descent 또는 adam을 선택할 수 있음) 더 많은 **에포크** 동안 트레이닝할 수 있습니다.

<Note>
* 상관 관계는 반드시 인과 관계가 아닌 연관성의 증거를 보여줍니다.
* 상관 관계는 이상치에 민감하며, 특히 시도한 하이퍼파라미터의 샘플 크기가 작은 경우 강한 관계를 보통 관계로 바꿀 수 있습니다.
* 마지막으로 상관 관계는 하이퍼파라미터와 메트릭 간의 선형 관계만 캡처합니다. 강한 다항 관계가 있는 경우 상관 관계에 의해 캡처되지 않습니다.
</Note>

중요도와 상관 관계의 차이는 중요도가 하이퍼파라미터 간의 상호 작용을 고려하는 반면 상관 관계는 개별 하이퍼파라미터가 메트릭 값에 미치는 영향만 측정한다는 사실에서 비롯됩니다. 둘째, 상관 관계는 선형 관계만 캡처하는 반면 중요도는 더 복잡한 관계를 캡처할 수 있습니다.

보시다시피 중요도와 상관 관계는 모두 하이퍼파라미터가 모델 성능에 미치는 영향을 이해하는 데 유용한 **툴**입니다.
