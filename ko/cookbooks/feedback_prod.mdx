---
- title: Feedback Prod
- description: W&B Weaveë¡œ í”¼ë“œë°± í”„ë¡œë•ì…˜ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²• ì•Œì•„ë³´ê¸°
---

<Note>
  ì´ê²ƒì€ ëŒ€í™”í˜• ë…¸íŠ¸ë¶ì…ë‹ˆë‹¤. ë¡œì»¬ì—ì„œ ì‹¤í–‰í•˜ê±°ë‚˜ ì•„ë˜ ë§í¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

  * [Open in Google Colab](https://colab.research.google.com/github/wandb/weave/blob/master/docs/notebooks/feedback_prod.ipynb)
  * [View source on GitHub](https://github.com/wandb/weave/blob/master/docs/notebooks/feedback_prod.ipynb)
</Note>

##

ìƒì„±ëœ LLM ì‘ë‹µì„ ìë™ìœ¼ë¡œ í‰ê°€í•˜ê¸°ëŠ” ì–´ë ¤ìš¸ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìœ„í—˜ í—ˆìš© ìˆ˜ì¤€ì— ë”°ë¼ ì§ì ‘ì ì¸ ì‚¬ìš©ì í”¼ë“œë°±ì„ ìˆ˜ì§‘í•˜ì—¬ ê°œì„  ì˜ì—­ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ì‚¬ìš©ì í”¼ë“œë°±ì„ ìˆ˜ì§‘í•˜ê¸° ìœ„í•œ ì˜ˆì œ ì•±ìœ¼ë¡œ ì»¤ìŠ¤í…€ ì±—ë´‡ì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.
ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•´ Streamlitì„ ì‚¬ìš©í•˜ê³  LLM ìƒí˜¸ì‘ìš©ê³¼ í”¼ë“œë°±ì„ Weaveì— ìº¡ì²˜í•  ê²ƒì…ë‹ˆë‹¤.

## ì„¤ì •

```python
!pip install weave openai streamlit wandb
!pip install set-env-colab-kaggle-dotenv -q # for env var
python
# Add a .env file with your OpenAI and WandB API keys
from set_env import set_env

_ = set_env("OPENAI_API_KEY")
_ = set_env("WANDB_API_KEY")
```

ë‹¤ìŒìœ¼ë¡œ, `chatbot.py` íŒŒì¼ì„ ë‹¤ìŒ ë‚´ìš©ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤:

```python
# chatbot.py

import openai
import streamlit as st
import wandb
from set_env import set_env

import weave

_ = set_env("OPENAI_API_KEY")
_ = set_env("WANDB_API_KEY")

# highlight-next-line
wandb.login()

# highlight-next-line
weave_client = weave.init("feedback-example")
oai_client = openai.OpenAI()

def init_states():
    """Set up session_state keys if they don't exist yet."""
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    if "calls" not in st.session_state:
        st.session_state["calls"] = []
    if "session_id" not in st.session_state:
        st.session_state["session_id"] = "123abc"

# highlight-next-line
@weave.op
def chat_response(full_history):
    """
    Calls the OpenAI API in streaming mode given the entire conversation history so far.
    full_history is a list of dicts: [{"role":"user"|"assistant","content":...}, ...]
    """
    stream = oai_client.chat.completions.create(
        model="gpt-4", messages=full_history, stream=True
    )
    response_text = st.write_stream(stream)
    return {"response": response_text}

def render_feedback_buttons(call_idx):
    """Renders thumbs up/down and text feedback for the call."""
    col1, col2, col3 = st.columns([1, 1, 4])

    # Thumbs up button
    with col1:
        if st.button("ğŸ‘", key=f"thumbs_up_{call_idx}"):
            st.session_state.calls[call_idx].feedback.add_reaction("ğŸ‘")
            st.success("Thanks for the feedback!")

    # Thumbs down button
    with col2:
        if st.button("ğŸ‘", key=f"thumbs_down_{call_idx}"):
            st.session_state.calls[call_idx].feedback.add_reaction("ğŸ‘")
            st.success("Thanks for the feedback!")

    # Text feedback
    with col3:
        feedback_text = st.text_input("Feedback", key=f"feedback_input_{call_idx}")
        if (
            st.button("Submit Feedback", key=f"submit_feedback_{call_idx}")
            and feedback_text
        ):
            st.session_state.calls[call_idx].feedback.add_note(feedback_text)
            st.success("Feedback submitted!")

def display_old_messages():
    """Displays the conversation stored in st.session_state.messages with feedback buttons"""
    for idx, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

            # If it's an assistant message, show feedback form
            if message["role"] == "assistant":
                # Figure out index of this assistant message in st.session_state.calls
                assistant_idx = (
                    len(
                        [
                            m
                            for m in st.session_state.messages[: idx + 1]
                            if m["role"] == "assistant"
                        ]
                    )
                    - 1
                )
                # Render thumbs up/down & text feedback
                if assistant_idx < len(st.session_state.calls):
                    render_feedback_buttons(assistant_idx)

def display_chat_prompt():
    """Displays the chat prompt input box."""
    if prompt := st.chat_input("Ask me anything!"):
        # Immediately render new user message
        with st.chat_message("user"):
            st.markdown(prompt)

        # Save user message in session
        st.session_state.messages.append({"role": "user", "content": prompt})

        # Prepare chat history for the API
        full_history = [
            {"role": msg["role"], "content": msg["content"]}
            for msg in st.session_state.messages
        ]

        with st.chat_message("assistant"):
            # Attach Weave attributes for tracking of conversation instances
            with weave.attributes(
                {"session": st.session_state["session_id"], "env": "prod"}
            ):
                # Call the OpenAI API (stream)
                result, call = chat_response.call(full_history)

                # Store the assistant message
                st.session_state.messages.append(
                    {"role": "assistant", "content": result["response"]}
                )

                # Store the weave call object to link feedback to the specific response
                st.session_state.calls.append(call)

                # Render feedback buttons for the new message
                new_assistant_idx = (
                    len(
                        [
                            m
                            for m in st.session_state.messages
                            if m["role"] == "assistant"
                        ]
                    )
                    - 1
                )

                # Render feedback buttons
                if new_assistant_idx < len(st.session_state.calls):
                    render_feedback_buttons(new_assistant_idx)

def main():
    st.title("Chatbot with immediate feedback forms")
    init_states()
    display_old_messages()
    display_chat_prompt()

if __name__ == "__main__":
    main()
```

ì´ê²ƒì„ `streamlit run chatbot.py`ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ì œ ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ìƒí˜¸ì‘ìš©í•˜ê³  ê° ì‘ë‹µ í›„ì— í”¼ë“œë°± ë²„íŠ¼ì„ í´ë¦­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
Weave UIë¥¼ ë°©ë¬¸í•˜ì—¬ ì²¨ë¶€ëœ í”¼ë“œë°±ì„ í™•ì¸í•˜ì„¸ìš”.

## ì„¤ëª…

ë°ì½”ë ˆì´í„°ê°€ ì ìš©ëœ ì˜ˆì¸¡ í•¨ìˆ˜ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
import weave

weave.init("feedback-example")

# highlight-next-line
@weave.op
def predict(input_data):
    # Your prediction logic here
    some_result = "hello world"
    return some_result
```

ì´ê²ƒì„ í‰ì†Œì²˜ëŸ¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ëª¨ë¸ ì‘ë‹µì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
with weave.attributes(
    {"session": "123abc", "env": "prod"}
):  # attach arbitrary attributes to the call alongside inputs & outputs
    result = predict(input_data="your data here")  # user question through the App UI
```

í”¼ë“œë°±ì„ ì²¨ë¶€í•˜ë ¤ë©´ `call` ê°ì²´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ëŠ” `.call()` ë©”ì„œë“œë¥¼ *ì¼ë°˜ì ìœ¼ë¡œ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” ëŒ€ì‹ * ì‚¬ìš©í•˜ì—¬ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
result, call = predict.call(input_data="your data here")
```

ì´ í˜¸ì¶œ ê°ì²´ëŠ” íŠ¹ì • ì‘ë‹µì— í”¼ë“œë°±ì„ ì²¨ë¶€í•˜ëŠ” ë° í•„ìš”í•©ë‹ˆë‹¤.
í˜¸ì¶œì„ í•œ í›„, ì‘ì—…ì˜ ì¶œë ¥ì€ ìœ„ì˜ `result`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
call.feedback.add_reaction("ğŸ‘")  # user reaction through the App UI
```

## ê²°ë¡ 

ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” Streamlitìœ¼ë¡œ ì±„íŒ… UIë¥¼ êµ¬ì¶•í–ˆìœ¼ë©°, ì…ë ¥ ë° ì¶œë ¥ì´ Weaveì— ìº¡ì²˜ë˜ê³  ì‚¬ìš©ì í”¼ë“œë°±ì„ ìº¡ì²˜í•˜ê¸° ìœ„í•œ ğŸ‘ğŸ‘ ë²„íŠ¼ì´ ìˆìŠµë‹ˆë‹¤.
